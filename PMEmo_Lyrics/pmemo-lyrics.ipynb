{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11863470,"sourceType":"datasetVersion","datasetId":7454873}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport time\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif, f_regression\nfrom skopt import BayesSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom sentence_transformers import SentenceTransformer\n\n\nANNOTATIONS_PATH = \"/kaggle/input/datasets/zheskychel/pmemo2019/PMEmo2019/annotations/static_annotations.csv\"\nLYRICS_PATH = \"/kaggle/input/datasets/zheskychel/pmemo2019/PMEmo2019/lyrics\"\n\nannotations = pd.read_csv(ANNOTATIONS_PATH)\nannotations = annotations.sort_values(\"musicId\").reset_index(drop=True)\n\n\ndef load_lyrics(music_id):\n    path = os.path.join(LYRICS_PATH, f\"{music_id}.lrc\")\n    try:\n        with open(path, encoding=\"utf-8\") as f:\n            return f.read()\n    except:\n        return \"\"\n\nannotations[\"lyrics\"] = annotations[\"musicId\"].apply(load_lyrics).fillna(\"\")\n\n\n#Text cleaning\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n    text = re.sub(r\"\\d+\", \"\", text)\n    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\nannotations[\"clean_lyrics\"] = annotations[\"lyrics\"].apply(clean_text)\n\n\n#BERT embeddings\nencoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\nX_text = encoder.encode(\n    annotations[\"clean_lyrics\"].tolist(),\n    show_progress_bar=True\n)\n\n#Targets\ny_val = annotations[\"Valence(mean)\"].values\ny_aro = annotations[\"Arousal(mean)\"].values\n\n\n#Split\nidx = np.arange(len(annotations))\n\nidx_train, idx_test = train_test_split(\n    idx,\n    test_size=0.2,\n    random_state=42\n)\n\n#TEXT only data\nX_train_val = X_text[idx_train]\nX_test_val  = X_text[idx_test]\n\nX_train_aro = X_text[idx_train]\nX_test_aro  = X_text[idx_test]\n\ny_val_train, y_val_test = y_val[idx_train], y_val[idx_test]\ny_aro_train, y_aro_test = y_aro[idx_train], y_aro[idx_test]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:43:49.348894Z","iopub.execute_input":"2026-02-13T02:43:49.349652Z","iopub.status.idle":"2026-02-13T02:43:52.899995Z","shell.execute_reply.started":"2026-02-13T02:43:49.349617Z","shell.execute_reply":"2026-02-13T02:43:52.899431Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8099ddc3bed84f89b978167fa6f7ce87"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom skopt import BayesSearchCV\n\nmodels = {\n    'Ridge': (\n        Ridge(),\n        {'alpha': (1e-3, 1e+3, 'log-uniform')}\n    ),\n\n    'SVR': (\n        SVR(),\n        {\n            'C': (1e-3, 1e+3, 'log-uniform'),\n            'gamma': (1e-4, 1e-1, 'log-uniform'),\n            'kernel': ['rbf']\n        }\n    ),\n\n    'Random Forest': (\n        RandomForestRegressor(),\n        {\n            'n_estimators': (100, 1000),\n            'max_depth': (5, 50),\n            'min_samples_split': (2, 20),\n            'min_samples_leaf': (1, 10)\n        }\n    ),\n\n    'XGBoost': (\n        XGBRegressor(\n            objective='reg:squarederror',\n            tree_method='hist',\n            device='cuda'\n        ),\n        {\n            'n_estimators': (100, 1000),\n            'max_depth': (3, 15),\n            'learning_rate': (1e-2, 3e-1, 'log-uniform'),\n            'subsample': (0.5, 1.0),\n            'colsample_bytree': (0.5, 1.0)\n        }\n    ),\n\n    'k-Nearest Neighbors': (\n        KNeighborsRegressor(),\n        {\n            'n_neighbors': (1, 30),\n            'weights': ['uniform', 'distance'],\n            'p': [1, 2]\n        }\n    )\n}\n\n\ndef reg_metrics(y_true, y_pred):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n\nresults_val = []\ntrained_models_val = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:43:52.901524Z","iopub.execute_input":"2026-02-13T02:43:52.901768Z","iopub.status.idle":"2026-02-13T02:43:52.908932Z","shell.execute_reply.started":"2026-02-13T02:43:52.901744Z","shell.execute_reply":"2026-02-13T02:43:52.908097Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, (model, param_grid) in tqdm(models.items()):\n    print(f\"\\nTraining {name}...\")\n\n    pipeline = Pipeline([('model', model)])\n\n    opt = BayesSearchCV(\n        estimator=pipeline,\n        search_spaces={'model__' + k: v for k, v in param_grid.items()},\n        n_iter=40,\n        scoring='neg_root_mean_squared_error',  # оптимизируем RMSE\n        cv=3,\n        n_jobs=-1,\n        verbose=0,\n        random_state=42,\n        refit=True,\n    )\n\n    opt.fit(X_train_val, y_val_train)\n\n    y_pred = opt.predict(X_test_val)\n\n    mae, rmse, r2 = reg_metrics(y_val_test, y_pred)\n\n    print(f\"Model: {name}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n\n    results_val.append({\n        'Model': name,\n        'Best Params': opt.best_params_,\n        'MAE': float(mae),\n        'RMSE': float(rmse),\n        'R2': float(r2),\n        'Best CV (neg_RMSE)': float(opt.best_score_),\n    })\n\n    trained_models_val[name] = opt\n\nresults_val_df = pd.DataFrame(results_val).sort_values(by='RMSE', ascending=True)\ndisplay(results_val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:43:52.909813Z","iopub.execute_input":"2026-02-13T02:43:52.910079Z","iopub.status.idle":"2026-02-13T03:27:53.022092Z","shell.execute_reply.started":"2026-02-13T02:43:52.910056Z","shell.execute_reply":"2026-02-13T03:27:53.021509Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nTraining Ridge...\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 1/5 [00:30<02:03, 30.85s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Ridge, MAE: 0.1143, RMSE: 0.1452, R2: 0.0988\n\nTraining SVR...\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [01:06<01:40, 33.57s/it]","output_type":"stream"},{"name":"stdout","text":"Model: SVR, MAE: 0.1128, RMSE: 0.1427, R2: 0.1291\n\nTraining Random Forest...\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [31:55<28:45, 862.53s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.1100, RMSE: 0.1396, R2: 0.1665\n\nTraining XGBoost...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [03:15:58] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [03:15:58] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [03:15:58] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [03:16:12] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [03:27:19] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n 80%|████████  | 4/5 [43:26<13:14, 794.89s/it]/usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.1114, RMSE: 0.1411, R2: 0.1494\n\nTraining k-Nearest Neighbors...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(19), np.int64(2), np.str_('uniform')] before, using random point [np.int64(12), np.int64(1), 'distance']\n  warnings.warn(\n100%|██████████| 5/5 [44:00<00:00, 528.01s/it]","output_type":"stream"},{"name":"stdout","text":"Model: k-Nearest Neighbors, MAE: 0.1163, RMSE: 0.1458, R2: 0.0914\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 Model                                        Best Params  \\\n2        Random Forest  {'model__max_depth': 47, 'model__min_samples_l...   \n3              XGBoost  {'model__colsample_bytree': 0.6414003480362944...   \n1                  SVR  {'model__C': 3.464647947339935, 'model__gamma'...   \n0                Ridge                {'model__alpha': 2.149646021368094}   \n4  k-Nearest Neighbors  {'model__n_neighbors': 24, 'model__p': 1, 'mod...   \n\n        MAE      RMSE        R2  Best CV (neg_RMSE)  \n2  0.109988  0.139645  0.166468           -0.151363  \n3  0.111428  0.141069  0.149381           -0.150148  \n1  0.112765  0.142742  0.129086           -0.150806  \n0  0.114299  0.145206  0.098757           -0.149429  \n4  0.116309  0.145794  0.091440           -0.148892  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>R2</th>\n      <th>Best CV (neg_RMSE)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 47, 'model__min_samples_l...</td>\n      <td>0.109988</td>\n      <td>0.139645</td>\n      <td>0.166468</td>\n      <td>-0.151363</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.6414003480362944...</td>\n      <td>0.111428</td>\n      <td>0.141069</td>\n      <td>0.149381</td>\n      <td>-0.150148</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>{'model__C': 3.464647947339935, 'model__gamma'...</td>\n      <td>0.112765</td>\n      <td>0.142742</td>\n      <td>0.129086</td>\n      <td>-0.150806</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 2.149646021368094}</td>\n      <td>0.114299</td>\n      <td>0.145206</td>\n      <td>0.098757</td>\n      <td>-0.149429</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k-Nearest Neighbors</td>\n      <td>{'model__n_neighbors': 24, 'model__p': 1, 'mod...</td>\n      <td>0.116309</td>\n      <td>0.145794</td>\n      <td>0.091440</td>\n      <td>-0.148892</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"results_val_df.to_csv('valence_regression_text_only_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:27:53.023650Z","iopub.execute_input":"2026-02-13T03:27:53.023876Z","iopub.status.idle":"2026-02-13T03:27:53.032943Z","shell.execute_reply.started":"2026-02-13T03:27:53.023853Z","shell.execute_reply":"2026-02-13T03:27:53.032336Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Arousal","metadata":{}},{"cell_type":"code","source":"import ast\nfrom sklearn.pipeline import Pipeline\n\ndef parse_best_params(x):\n    if isinstance(x, dict):\n        return x\n    if isinstance(x, str):\n        x = x.strip()\n        if not x:\n            return {}\n        return ast.literal_eval(x)\n    return {}\n\n#Model -> Best Params (FROM VALENCE TUNING)\nbest_params_map = {\n    row[\"Model\"]: parse_best_params(row[\"Best Params\"])\n    for _, row in results_val_df.iterrows()\n}\n\nresults_aro = []\ntrained_models_aro = {}\n\nfor name, (model, param_grid) in tqdm(models.items()):\n    print(f\"\\nRefit {name} with params from results_val_df...\")\n\n    if name not in best_params_map:\n        print(f\"[SKIP] {name} not found in results_val_df\")\n        continue\n\n    best_params = best_params_map[name]\n    pipeline = Pipeline([('model', model)])\n\n    if best_params:\n        pipeline.set_params(**best_params)\n\n    pipeline.fit(X_train_aro, y_aro_train)\n    y_pred = pipeline.predict(X_test_aro)\n\n    mae, rmse, r2 = reg_metrics(y_aro_test, y_pred)\n\n    print(f\"Model: {name}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n\n    results_aro.append({\n        \"Model\": name,\n        \"Best Params\": best_params,\n        \"MAE\": float(mae),\n        \"RMSE\": float(rmse),\n        \"R2\": float(r2),\n    })\n\n    trained_models_aro[name] = pipeline\n\nresults_aro_df = pd.DataFrame(results_aro).sort_values(by=\"RMSE\", ascending=True).reset_index(drop=True)\ndisplay(results_aro_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:28:39.048228Z","iopub.execute_input":"2026-02-13T03:28:39.048768Z","iopub.status.idle":"2026-02-13T03:29:05.119102Z","shell.execute_reply.started":"2026-02-13T03:28:39.048733Z","shell.execute_reply":"2026-02-13T03:29:05.118509Z"}},"outputs":[{"name":"stderr","text":" 20%|██        | 1/5 [00:00<00:00,  6.82it/s]","output_type":"stream"},{"name":"stdout","text":"\nRefit Ridge with params from results_val_df...\nModel: Ridge, MAE: 0.1465, RMSE: 0.1803, R2: 0.0412\n\nRefit SVR with params from results_val_df...\nModel: SVR, MAE: 0.1477, RMSE: 0.1822, R2: 0.0208\n\nRefit Random Forest with params from results_val_df...\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [00:12<00:09,  4.72s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.1469, RMSE: 0.1800, R2: 0.0438\n\nRefit XGBoost with params from results_val_df...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:26<00:00,  5.21s/it]","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.1454, RMSE: 0.1810, R2: 0.0335\n\nRefit k-Nearest Neighbors with params from results_val_df...\nModel: k-Nearest Neighbors, MAE: 0.1501, RMSE: 0.1871, R2: -0.0330\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 Model                                        Best Params  \\\n0        Random Forest  {'model__max_depth': 47, 'model__min_samples_l...   \n1                Ridge                {'model__alpha': 2.149646021368094}   \n2              XGBoost  {'model__colsample_bytree': 0.6414003480362944...   \n3                  SVR  {'model__C': 3.464647947339935, 'model__gamma'...   \n4  k-Nearest Neighbors  {'model__n_neighbors': 24, 'model__p': 1, 'mod...   \n\n        MAE      RMSE        R2  \n0  0.146859  0.180035  0.043828  \n1  0.146493  0.180285  0.041180  \n2  0.145381  0.181004  0.033509  \n3  0.147702  0.182188  0.020824  \n4  0.150113  0.187129 -0.032999  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 47, 'model__min_samples_l...</td>\n      <td>0.146859</td>\n      <td>0.180035</td>\n      <td>0.043828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 2.149646021368094}</td>\n      <td>0.146493</td>\n      <td>0.180285</td>\n      <td>0.041180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.6414003480362944...</td>\n      <td>0.145381</td>\n      <td>0.181004</td>\n      <td>0.033509</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVR</td>\n      <td>{'model__C': 3.464647947339935, 'model__gamma'...</td>\n      <td>0.147702</td>\n      <td>0.182188</td>\n      <td>0.020824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k-Nearest Neighbors</td>\n      <td>{'model__n_neighbors': 24, 'model__p': 1, 'mod...</td>\n      <td>0.150113</td>\n      <td>0.187129</td>\n      <td>-0.032999</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"results_aro_df.to_csv('arousal_regression_text_only_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:30:22.975155Z","iopub.execute_input":"2026-02-13T03:30:22.975620Z","iopub.status.idle":"2026-02-13T03:30:22.980929Z","shell.execute_reply.started":"2026-02-13T03:30:22.975586Z","shell.execute_reply":"2026-02-13T03:30:22.980310Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n\n#Russell model of emotion\ndef assign_quadrant(valence, arousal, thr=0.5):\n    if valence <= thr and arousal <= thr:\n        return 2\n    elif valence > thr and arousal <= thr:\n        return 3\n    elif valence <= thr and arousal > thr:\n        return 1\n    else:\n        return 0\n\ndef quadrant_vec(v, a, thr=0.5):\n    v = np.asarray(v).ravel()\n    a = np.asarray(a).ravel()\n    return np.array([assign_quadrant(v[i], a[i], thr=thr) for i in range(len(v))], dtype=int)\n    \ny_true_quad = quadrant_vec(y_val_test, y_aro_test, thr=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:30:33.074742Z","iopub.execute_input":"2026-02-13T03:30:33.075369Z","iopub.status.idle":"2026-02-13T03:30:33.081261Z","shell.execute_reply.started":"2026-02-13T03:30:33.075337Z","shell.execute_reply":"2026-02-13T03:30:33.080428Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ndef reg_metrics(y_true, y_pred):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n\ntrained_models_val = dict(trained_models_val)\ntrained_models_aro = dict(trained_models_aro)\n\n#Valence LinearRegression\nlin_val = LinearRegression()\nlin_val.fit(X_train_val, y_val_train)\nv_pred = lin_val.predict(X_test_val)\nmae_v, rmse_v, r2_v = reg_metrics(y_val_test, v_pred)\nprint(f\"LinearReg (Valence): MAE={mae_v:.4f} RMSE={rmse_v:.4f} R2={r2_v:.4f}\")\n\ntrained_models_val[\"Linear Regression\"] = lin_val\n\n#Arousal LinearRegression\nlin_aro = LinearRegression()\nlin_aro.fit(X_train_aro, y_aro_train)\na_pred = lin_aro.predict(X_test_aro)\nmae_a, rmse_a, r2_a = reg_metrics(y_aro_test, a_pred)\nprint(f\"LinearReg (Arousal): MAE={mae_a:.4f} RMSE={rmse_a:.4f} R2={r2_a:.4f}\")\n\ntrained_models_aro[\"Linear Regression\"] = lin_aro","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:30:33.082431Z","iopub.execute_input":"2026-02-13T03:30:33.082752Z","iopub.status.idle":"2026-02-13T03:30:33.180124Z","shell.execute_reply.started":"2026-02-13T03:30:33.082727Z","shell.execute_reply":"2026-02-13T03:30:33.179443Z"}},"outputs":[{"name":"stdout","text":"LinearReg (Valence): MAE=0.2078 RMSE=0.2688 R2=-2.0888\nLinearReg (Arousal): MAE=0.2647 RMSE=0.3552 R2=-2.7229\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_quad = []\n\ncommon_models = sorted(set(trained_models_val.keys()) & set(trained_models_aro.keys()))\n\nfor name in common_models:\n    model_val = trained_models_val[name]\n    model_aro = trained_models_aro[name]\n\n    v_pred = model_val.predict(X_test_val)\n    a_pred = model_aro.predict(X_test_aro)\n\n    y_pred_quad = quadrant_vec(v_pred, a_pred, thr=0.5)\n\n    acc = accuracy_score(y_true_quad, y_pred_quad)\n\n    # weighted metrics\n    f1 = f1_score(y_true_quad, y_pred_quad, average=\"weighted\")\n    prec, rec, _, _ = precision_recall_fscore_support(\n        y_true_quad,\n        y_pred_quad,\n        average=\"weighted\",\n        zero_division=0\n    )\n\n    results_quad.append({\n        \"Model\": name,\n        \"Accuracy\": float(acc),\n        \"Precision\": float(prec),\n        \"Recall\": float(rec),\n        \"F1\": float(f1),\n    })\n\nresults_quad_df = (\n    pd.DataFrame(results_quad)\n    .sort_values(\"F1\", ascending=False)\n    .reset_index(drop=True)\n)\n\ndisplay(results_quad_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:30:33.181065Z","iopub.execute_input":"2026-02-13T03:30:33.181353Z","iopub.status.idle":"2026-02-13T03:30:33.501653Z","shell.execute_reply.started":"2026-02-13T03:30:33.181323Z","shell.execute_reply":"2026-02-13T03:30:33.500984Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                 Model  Accuracy  Precision    Recall        F1\n0                Ridge  0.642857   0.652909  0.642857  0.579672\n1                  SVR  0.649351   0.672873  0.649351  0.569161\n2              XGBoost  0.642857   0.600383  0.642857  0.567705\n3        Random Forest  0.668831   0.489508  0.668831  0.564706\n4    Linear Regression  0.558442   0.559673  0.558442  0.556652\n5  k-Nearest Neighbors  0.616883   0.667798  0.616883  0.551582","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>0.642857</td>\n      <td>0.652909</td>\n      <td>0.642857</td>\n      <td>0.579672</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>0.649351</td>\n      <td>0.672873</td>\n      <td>0.649351</td>\n      <td>0.569161</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBoost</td>\n      <td>0.642857</td>\n      <td>0.600383</td>\n      <td>0.642857</td>\n      <td>0.567705</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>0.668831</td>\n      <td>0.489508</td>\n      <td>0.668831</td>\n      <td>0.564706</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Linear Regression</td>\n      <td>0.558442</td>\n      <td>0.559673</td>\n      <td>0.558442</td>\n      <td>0.556652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>k-Nearest Neighbors</td>\n      <td>0.616883</td>\n      <td>0.667798</td>\n      <td>0.616883</td>\n      <td>0.551582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"results_quad_df.to_csv('PMEmo_classification_text_only_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:31:24.405964Z","iopub.execute_input":"2026-02-13T03:31:24.406730Z","iopub.status.idle":"2026-02-13T03:31:24.411721Z","shell.execute_reply.started":"2026-02-13T03:31:24.406695Z","shell.execute_reply":"2026-02-13T03:31:24.411014Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}