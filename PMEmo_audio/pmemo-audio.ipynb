{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11624006,"sourceType":"datasetVersion","datasetId":7292338},{"sourceId":14823982,"sourceType":"datasetVersion","datasetId":9480384}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:14:43.441734Z","iopub.execute_input":"2026-02-13T04:14:43.442205Z","iopub.status.idle":"2026-02-13T04:14:43.448735Z","shell.execute_reply.started":"2026-02-13T04:14:43.442181Z","shell.execute_reply":"2026-02-13T04:14:43.448148Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_regression\n\n\nANNOTATIONS_PATH = \"/kaggle/input/pmemo-2019/PMEmo2019/annotations/static_annotations.csv\"\nFEATURES_PATH = \"/kaggle/input/pmemo-2019/PMEmo2019/features/static_features.csv\"\nannotations = pd.read_csv(ANNOTATIONS_PATH)\nfeatures = pd.read_csv(FEATURES_PATH)\n\n\n\nfeatures = features.sort_values(by=\"musicId\").reset_index(drop=True)\nannotations = annotations.sort_values(by=\"musicId\").reset_index(drop=True)\n\n\nmerged = pd.merge(features, annotations, on='musicId', how='inner')\n\n\nX = merged.drop(columns=['musicId', 'Arousal(mean)', 'Valence(mean)'])\ny_valence = merged['Valence(mean)']\ny_arousal = merged['Arousal(mean)']\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n\n#Valence Features\nselector_valence = SelectKBest(score_func=f_regression, k=400)\nX_valence = selector_valence.fit_transform(X_scaled, y_valence)\n\n\n#Arousal Features\nselector_arousal = SelectKBest(score_func=f_regression, k=400)\nX_arousal = selector_arousal.fit_transform(X_scaled, y_arousal)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:14:47.961767Z","iopub.execute_input":"2026-02-13T04:14:47.962037Z","iopub.status.idle":"2026-02-13T04:14:50.796907Z","shell.execute_reply.started":"2026-02-13T04:14:47.962017Z","shell.execute_reply":"2026-02-13T04:14:50.796068Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"X_valence.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:14:53.912918Z","iopub.execute_input":"2026-02-13T04:14:53.913836Z","iopub.status.idle":"2026-02-13T04:14:53.920241Z","shell.execute_reply.started":"2026-02-13T04:14:53.913803Z","shell.execute_reply":"2026-02-13T04:14:53.919406Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(767, 400)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import time\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom skopt import BayesSearchCV\nfrom tqdm import tqdm\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_valence, y_valence, test_size=0.2, random_state=42\n)\n\n\nmodels = {\n        \n    'XGBoost': (\n    XGBRegressor(\n        objective='reg:squarederror',\n        tree_method='hist'\n    ),\n        {\n            'n_estimators': (100, 1400),\n            'max_depth': (3, 25),\n            'learning_rate': (0.01, 0.05),\n            'subsample': (0.3, 1.0),\n            'colsample_bytree': (0.3, 1.0)\n        }\n    ),\n    \n    \n    'Ridge': (\n        Ridge(),\n        {'alpha': (1e-3, 1e+3, 'log-uniform')}\n    ),\n    \n    'SVR': (\n        SVR(),\n        {\n            'C': (1e-3, 1e+3, 'log-uniform'),\n            'gamma': (1e-4, 1e-1, 'log-uniform'),\n            'kernel': ['rbf']\n        }\n    ),\n    \n    'Random Forest': (\n        RandomForestRegressor(),\n        {\n            'n_estimators': (100, 1400),\n            'max_depth': (5, 70),\n            'min_samples_split': (2, 40),\n            'min_samples_leaf': (1, 20)\n        }\n    ),\n    \n    'kNN': (\n        KNeighborsRegressor(),\n        {\n            'n_neighbors': (1, 35),\n            'weights': ['uniform', 'distance'],\n            'p': [1, 2]\n        }\n    )\n}\n\n\nresults_valence = []\n\nfor name, (model, param_grid) in tqdm(models.items()):\n    print(f\"\\nTraining {name}\")\n    \n    pipeline = Pipeline([('model', model)])\n    \n    opt = BayesSearchCV(\n        pipeline,\n        {'model__' + k: v for k, v in param_grid.items()},\n        n_iter=30,\n        scoring='neg_mean_squared_error',\n        cv=3,\n        n_jobs=-1,\n        verbose=0,\n        random_state=42\n    )\n    \n\n    start_train = time.time()\n    opt.fit(X_train, y_train)\n    end_train = time.time()\n    train_time = end_train - start_train\n    \n\n    start_pred = time.time()\n    y_pred = opt.predict(X_test)\n    end_pred = time.time()\n    pred_time = end_pred - start_pred\n    \n\n    rmse = mean_squared_error(y_test, y_pred, squared=False)\n    mae = mean_absolute_error(y_test, y_pred)\n    print(f'Model: {name}, MAE: {mae}, RMSE: {rmse}')\n    \n\n    results_valence.append({\n        'Model': name,\n        'Best Params': opt.best_params_,\n        'RMSE': rmse,\n        'MAE': mae,\n        'Train Time (s)': train_time,\n        'Inference Time (s)': pred_time\n    })\n\nresults_valence_df = pd.DataFrame(results_valence)\nresults_valence_df = results_valence_df.sort_values(by='RMSE').reset_index(drop=True)\n\nprint(\"Valence\")\ndisplay(results_valence_df)\n\nresults_valence_df.to_csv('valence_regression_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T23:17:33.078205Z","iopub.execute_input":"2026-02-12T23:17:33.078396Z","iopub.status.idle":"2026-02-12T23:53:47.402170Z","shell.execute_reply.started":"2026-02-12T23:17:33.078383Z","shell.execute_reply":"2026-02-12T23:53:47.401348Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nTraining XGBoost\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 1/6 [36:14<3:01:11, 2174.30s/it]","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.08768523454385006, RMSE: 0.11183627088677248\n\nTraining Linear Regression\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/267344556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     opt = BayesSearchCV(\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'model__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, search_spaces, optimizer_kwargs, n_iter, scoring, fit_params, n_jobs, n_points, iid, refit, cv, verbose, pre_dispatch, random_state, error_score, return_train_score)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_search_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_spaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;31m# Temporary fix for compatibility with sklearn 0.20 and 0.21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# See scikit-optimize#762\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_check_search_space\u001b[0;34m(self, search_space)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;34m\"The search_spaces parameter should contain at least one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;34m\"non-empty search space, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The search_spaces parameter should contain at least onenon-empty search space, got {}"],"ename":"ValueError","evalue":"The search_spaces parameter should contain at least onenon-empty search space, got {}","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"models_nnn = {\n    \n    'Ridge': (\n        Ridge(),\n        {'alpha': (1e-3, 1e+3, 'log-uniform')}\n    ),\n    \n    'SVR': (\n        SVR(),\n        {\n            'C': (1e-3, 1e+3, 'log-uniform'),\n            'gamma': (1e-4, 1e-1, 'log-uniform'),\n            'kernel': ['rbf']\n        }\n    ),\n    \n    'Random Forest': (\n        RandomForestRegressor(),\n        {\n            'n_estimators': (100, 1400),\n            'max_depth': (5, 70),\n            'min_samples_split': (2, 40),\n            'min_samples_leaf': (1, 20)\n        }\n    ),\n    \n    'kNN': (\n        KNeighborsRegressor(),\n        {\n            'n_neighbors': (1, 35),\n            'weights': ['uniform', 'distance'],\n            'p': [1, 2]\n        }\n    )\n}\n\nfor name, (model, param_grid) in tqdm(models_nnn.items()):\n    print(f\"\\nTraining {name}\")\n    \n    pipeline = Pipeline([('model', model)])\n    \n    opt = BayesSearchCV(\n        pipeline,\n        {'model__' + k: v for k, v in param_grid.items()},\n        n_iter=30,\n        scoring='neg_mean_squared_error',\n        cv=3,\n        n_jobs=-1,\n        verbose=0,\n        random_state=42\n    )\n    \n\n    start_train = time.time()\n    opt.fit(X_train, y_train)\n    end_train = time.time()\n    train_time = end_train - start_train\n    \n\n    start_pred = time.time()\n    y_pred = opt.predict(X_test)\n    end_pred = time.time()\n    pred_time = end_pred - start_pred\n    \n\n    rmse = mean_squared_error(y_test, y_pred, squared=False)\n    mae = mean_absolute_error(y_test, y_pred)\n    print(f'Model: {name}, MAE: {mae}, RMSE: {rmse}')\n    \n\n    results_valence.append({\n        'Model': name,\n        'Best Params': opt.best_params_,\n        'RMSE': rmse,\n        'MAE': mae,\n        'Train Time (s)': train_time,\n        'Inference Time (s)': pred_time\n    })\n\nresults_valence_df = pd.DataFrame(results_valence)\nresults_valence_df = results_valence_df.sort_values(by='RMSE').reset_index(drop=True)\n\nprint(\"Valence\")\ndisplay(results_valence_df)\n\nresults_valence_df.to_csv('valence_regression_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:02:05.582524Z","iopub.execute_input":"2026-02-13T00:02:05.583142Z","iopub.status.idle":"2026-02-13T00:23:01.638723Z","shell.execute_reply.started":"2026-02-13T00:02:05.583117Z","shell.execute_reply":"2026-02-13T00:23:01.638006Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nTraining Ridge\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1/4 [00:17<00:51, 17.27s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Ridge, MAE: 0.08956046894279142, RMSE: 0.11498066749493462\n\nTraining SVR\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2/4 [00:35<00:35, 17.67s/it]","output_type":"stream"},{"name":"stdout","text":"Model: SVR, MAE: 0.08996119857800695, RMSE: 0.1138006814503485\n\nTraining Random Forest\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [20:40<09:19, 559.78s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.08936826175554394, RMSE: 0.11312013027052063\n\nTraining kNN\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [20:56<00:00, 314.01s/it]","output_type":"stream"},{"name":"stdout","text":"Model: kNN, MAE: 0.0919506510873016, RMSE: 0.11516823442278097\nValence\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           Model                                        Best Params      RMSE  \\\n0        XGBoost  {'model__colsample_bytree': 0.9400391622985333...  0.111836   \n1  Random Forest  {'model__max_depth': 24, 'model__min_samples_l...  0.113120   \n2            SVR  {'model__C': 1.7322493477589913, 'model__gamma...  0.113801   \n3          Ridge                {'model__alpha': 299.7879984490512}  0.114981   \n4            kNN  {'model__n_neighbors': 31, 'model__p': 2, 'mod...  0.115168   \n\n        MAE  Train Time (s)  Inference Time (s)  \n0  0.087685     2174.280951            0.005671  \n1  0.089368     1204.842289            0.046436  \n2  0.089961       17.918732            0.014295  \n3  0.089560       17.265595            0.002172  \n4  0.091951       15.874228            0.025952  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>RMSE</th>\n      <th>MAE</th>\n      <th>Train Time (s)</th>\n      <th>Inference Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.9400391622985333...</td>\n      <td>0.111836</td>\n      <td>0.087685</td>\n      <td>2174.280951</td>\n      <td>0.005671</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.113120</td>\n      <td>0.089368</td>\n      <td>1204.842289</td>\n      <td>0.046436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVR</td>\n      <td>{'model__C': 1.7322493477589913, 'model__gamma...</td>\n      <td>0.113801</td>\n      <td>0.089961</td>\n      <td>17.918732</td>\n      <td>0.014295</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 299.7879984490512}</td>\n      <td>0.114981</td>\n      <td>0.089560</td>\n      <td>17.265595</td>\n      <td>0.002172</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kNN</td>\n      <td>{'model__n_neighbors': 31, 'model__p': 2, 'mod...</td>\n      <td>0.115168</td>\n      <td>0.091951</td>\n      <td>15.874228</td>\n      <td>0.025952</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"models_nnn = {\n\n    'XGBoost': (\n    XGBRegressor(\n        objective='reg:squarederror',\n        tree_method='hist'\n    ),\n        {\n            'n_estimators': (100, 1400),\n            'max_depth': (3, 25),\n            'learning_rate': (0.01, 0.05),\n            'subsample': (0.3, 1.0),\n            'colsample_bytree': (0.3, 1.0)\n        }\n    ),\n    \n    'Ridge': (\n        Ridge(),\n        {'alpha': (1e-3, 1e+3, 'log-uniform')}\n    ),\n    \n    'SVR': (\n        SVR(),\n        {\n            'C': (1e-3, 1e+3, 'log-uniform'),\n            'gamma': (1e-4, 1e-1, 'log-uniform'),\n            'kernel': ['rbf']\n        }\n    ),\n    \n    'Random Forest': (\n        RandomForestRegressor(),\n        {\n            'n_estimators': (100, 1400),\n            'max_depth': (5, 70),\n            'min_samples_split': (2, 40),\n            'min_samples_leaf': (1, 20)\n        }\n    ),\n    \n    'kNN': (\n        KNeighborsRegressor(),\n        {\n            'n_neighbors': (1, 35),\n            'weights': ['uniform', 'distance'],\n            'p': [1, 2]\n        }\n    )\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:27:40.068078Z","iopub.execute_input":"2026-02-13T00:27:40.068320Z","iopub.status.idle":"2026-02-13T00:27:40.074142Z","shell.execute_reply.started":"2026-02-13T00:27:40.068302Z","shell.execute_reply":"2026-02-13T00:27:40.073356Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X_arousal, y_arousal, test_size=0.2, random_state=42\n)\n\nresults_arousal = []\n\nfor name, (model, param_grid) in tqdm(models_nnn.items()):\n    print(f\"\\n Training: {name}\")\n    \n    pipeline = Pipeline([('model', model)])\n    \n    opt = BayesSearchCV(\n        pipeline,\n        {'model__' + k: v for k, v in param_grid.items()},\n        n_iter=30,\n        scoring='neg_mean_squared_error',\n        cv=3,\n        n_jobs=-1,\n        verbose=0,\n        random_state=42\n    )\n    \n\n    start_train = time.time()\n    opt.fit(X_train, y_train)\n    end_train = time.time()\n    train_time = end_train - start_train\n    \n\n    start_pred = time.time()\n    y_pred = opt.predict(X_test)\n    end_pred = time.time()\n    pred_time = end_pred - start_pred\n    \n\n    rmse = mean_squared_error(y_test, y_pred, squared=False)\n    mae = mean_absolute_error(y_test, y_pred)\n    print(f'Model: {name}, MAE: {mae}, RMSE: {rmse}')\n    \n\n    results_arousal.append({\n        'Model': name,\n        'Best Params': opt.best_params_,\n        'RMSE': rmse,\n        'MAE': mae,\n        'Train Time (s)': train_time,\n        'Inference Time (s)': pred_time\n    })\n\n\n\nresults_arousal_df = pd.DataFrame(results_arousal)\nresults_arousal_df = results_arousal_df.sort_values(by='RMSE').reset_index(drop=True)\n\nprint(\"Arousal:\")\ndisplay(results_arousal_df)\n\nresults_arousal_df.to_csv('arousal_regression_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:27:53.548442Z","iopub.execute_input":"2026-02-13T00:27:53.548935Z","iopub.status.idle":"2026-02-13T01:22:12.208519Z","shell.execute_reply.started":"2026-02-13T00:27:53.548904Z","shell.execute_reply":"2026-02-13T01:22:12.207677Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n Training: XGBoost\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 1/5 [36:13<2:24:55, 2173.87s/it]","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.07280545247347336, RMSE: 0.09845101464890176\n\n Training: Ridge\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [36:29<45:12, 904.12s/it]   ","output_type":"stream"},{"name":"stdout","text":"Model: Ridge, MAE: 0.0731724524807826, RMSE: 0.09506634981962096\n\n Training: SVR\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [36:47<16:39, 499.75s/it]","output_type":"stream"},{"name":"stdout","text":"Model: SVR, MAE: 0.07295508784469505, RMSE: 0.09531350713696297\n\n Training: Random Forest\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 4/5 [54:02<11:50, 710.87s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.07406369532795407, RMSE: 0.09979286340357696\n\n Training: kNN\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [54:18<00:00, 651.73s/it]","output_type":"stream"},{"name":"stdout","text":"Model: kNN, MAE: 0.07520338661056082, RMSE: 0.10087263455671898\nArousal:\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           Model                                        Best Params      RMSE  \\\n0          Ridge                {'model__alpha': 569.0560928291766}  0.095066   \n1            SVR  {'model__C': 1.7822044492040485, 'model__gamma...  0.095314   \n2        XGBoost  {'model__colsample_bytree': 0.708964133941113,...  0.098451   \n3  Random Forest  {'model__max_depth': 70, 'model__min_samples_l...  0.099793   \n4            kNN  {'model__n_neighbors': 16, 'model__p': 1, 'mod...  0.100873   \n\n        MAE  Train Time (s)  Inference Time (s)  \n0  0.073172       15.283967            0.003298  \n1  0.072955       18.520894            0.011618  \n2  0.072805     2173.858640            0.003211  \n3  0.074064     1034.451573            0.046650  \n4  0.075203       16.386310            0.023483  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>RMSE</th>\n      <th>MAE</th>\n      <th>Train Time (s)</th>\n      <th>Inference Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 569.0560928291766}</td>\n      <td>0.095066</td>\n      <td>0.073172</td>\n      <td>15.283967</td>\n      <td>0.003298</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>{'model__C': 1.7822044492040485, 'model__gamma...</td>\n      <td>0.095314</td>\n      <td>0.072955</td>\n      <td>18.520894</td>\n      <td>0.011618</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.708964133941113,...</td>\n      <td>0.098451</td>\n      <td>0.072805</td>\n      <td>2173.858640</td>\n      <td>0.003211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 70, 'model__min_samples_l...</td>\n      <td>0.099793</td>\n      <td>0.074064</td>\n      <td>1034.451573</td>\n      <td>0.046650</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kNN</td>\n      <td>{'model__n_neighbors': 16, 'model__p': 1, 'mod...</td>\n      <td>0.100873</td>\n      <td>0.075203</td>\n      <td>16.386310</td>\n      <td>0.023483</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"results_arousal_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T01:22:44.538426Z","iopub.execute_input":"2026-02-13T01:22:44.539048Z","iopub.status.idle":"2026-02-13T01:22:44.548836Z","shell.execute_reply.started":"2026-02-13T01:22:44.539021Z","shell.execute_reply":"2026-02-13T01:22:44.548199Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"           Model                                        Best Params      RMSE  \\\n0          Ridge                {'model__alpha': 569.0560928291766}  0.095066   \n1            SVR  {'model__C': 1.7822044492040485, 'model__gamma...  0.095314   \n2        XGBoost  {'model__colsample_bytree': 0.708964133941113,...  0.098451   \n3  Random Forest  {'model__max_depth': 70, 'model__min_samples_l...  0.099793   \n4            kNN  {'model__n_neighbors': 16, 'model__p': 1, 'mod...  0.100873   \n\n        MAE  Train Time (s)  Inference Time (s)  \n0  0.073172       15.283967            0.003298  \n1  0.072955       18.520894            0.011618  \n2  0.072805     2173.858640            0.003211  \n3  0.074064     1034.451573            0.046650  \n4  0.075203       16.386310            0.023483  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>RMSE</th>\n      <th>MAE</th>\n      <th>Train Time (s)</th>\n      <th>Inference Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 569.0560928291766}</td>\n      <td>0.095066</td>\n      <td>0.073172</td>\n      <td>15.283967</td>\n      <td>0.003298</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>{'model__C': 1.7822044492040485, 'model__gamma...</td>\n      <td>0.095314</td>\n      <td>0.072955</td>\n      <td>18.520894</td>\n      <td>0.011618</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.708964133941113,...</td>\n      <td>0.098451</td>\n      <td>0.072805</td>\n      <td>2173.858640</td>\n      <td>0.003211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 70, 'model__min_samples_l...</td>\n      <td>0.099793</td>\n      <td>0.074064</td>\n      <td>1034.451573</td>\n      <td>0.046650</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kNN</td>\n      <td>{'model__n_neighbors': 16, 'model__p': 1, 'mod...</td>\n      <td>0.100873</td>\n      <td>0.075203</td>\n      <td>16.386310</td>\n      <td>0.023483</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"results_arousal_df\nresults_valence_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Models Training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nidx = np.arange(len(X_arousal))\n\nidx_train, idx_test = train_test_split(\n    idx,\n    test_size=0.1,\n    random_state=42\n)\n\nX_train_aro = X_arousal[idx_train]\nX_test_aro  = X_arousal[idx_test]\n\ny_train_aro = y_arousal[idx_train]\ny_test_aro = y_arousal[idx_test]\n\n\n\nX_train_val = X_valence[idx_train]\nX_test_val  = X_valence[idx_test]\n\ny_train_val = y_valence[idx_train]\ny_test_val = y_valence[idx_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:40:40.088063Z","iopub.execute_input":"2026-02-13T04:40:40.088566Z","iopub.status.idle":"2026-02-13T04:40:40.098766Z","shell.execute_reply.started":"2026-02-13T04:40:40.088544Z","shell.execute_reply":"2026-02-13T04:40:40.098001Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import ast\nimport joblib\nfrom sklearn.pipeline import Pipeline\n\ndef _ensure_dict(x):\n    if isinstance(x, dict):\n        return x\n    if isinstance(x, str):\n        x = x.strip()\n        if not x:\n            return {}\n        try:\n            return ast.literal_eval(x)\n        except Exception:\n            raise ValueError(f\"Cannot parse Best Params string: {x[:200]}\")\n    return {}\n\ndef refit_best_models(results_df, models_dict, X_train, y_train, *,\n                      save_dir=None, prefix=\"\"):\n\n    refit = {}\n\n    for _, row in results_df.iterrows():\n        name = row[\"Model\"]\n        best_params = _ensure_dict(row[\"Best Params\"])\n\n        if name not in models_dict:\n            print(f\"[WARN] '{name}' нет в models_dict — пропускаю\")\n            continue\n\n        base_estimator = models_dict[name][0]\n        pipe = Pipeline([(\"model\", base_estimator)])\n\n\n        if best_params:\n            pipe.set_params(**best_params)\n\n        pipe.fit(X_train, y_train)\n\n        refit[name] = pipe\n\n        if save_dir is not None:\n            safe_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n            joblib.dump(pipe, f\"{save_dir}/{prefix}{safe_name}.joblib\")\n\n    return refit\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T01:58:33.606790Z","iopub.execute_input":"2026-02-13T01:58:33.607057Z","iopub.status.idle":"2026-02-13T01:58:33.616607Z","shell.execute_reply.started":"2026-02-13T01:58:33.607033Z","shell.execute_reply":"2026-02-13T01:58:33.615955Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"best_models_arousal = refit_best_models(\n    results_df=results_arousal_df,\n    models_dict=models_nnn,\n    X_train=X_train_aro,\n    y_train=y_train_aro,\n    save_dir=None,\n    prefix=\"arousal_\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T01:58:33.617334Z","iopub.execute_input":"2026-02-13T01:58:33.617556Z","iopub.status.idle":"2026-02-13T02:00:54.271471Z","shell.execute_reply.started":"2026-02-13T01:58:33.617537Z","shell.execute_reply":"2026-02-13T02:00:54.270654Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"best_models_valence = refit_best_models(\n    results_df=results_valence_df,\n    models_dict=models_nnn,\n    X_train=X_train_val,\n    y_train=y_train_val,\n    save_dir=None,\n    prefix=\"valence_\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:00:54.272869Z","iopub.execute_input":"2026-02-13T02:00:54.273163Z","iopub.status.idle":"2026-02-13T02:04:08.120985Z","shell.execute_reply.started":"2026-02-13T02:00:54.273144Z","shell.execute_reply":"2026-02-13T02:04:08.120297Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n\n#Russell model of emotion\ndef assign_quadrant(valence, arousal, thr=0.5):\n    if valence <= thr and arousal <= thr:\n        return 2\n    elif valence > thr and arousal <= thr:\n        return 3\n    elif valence <= thr and arousal > thr:\n        return 1\n    else:\n        return 0\n\ndef quadrant_vec(v, a, thr=0.5):\n    v = np.asarray(v).ravel()\n    a = np.asarray(a).ravel()\n    return np.array([assign_quadrant(v[i], a[i], thr=thr) for i in range(len(v))], dtype=int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:04:08.121559Z","iopub.execute_input":"2026-02-13T02:04:08.121764Z","iopub.status.idle":"2026-02-13T02:04:08.131483Z","shell.execute_reply.started":"2026-02-13T02:04:08.121744Z","shell.execute_reply":"2026-02-13T02:04:08.130728Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"y_true_quad = quadrant_vec(y_test_val, y_test_aro, thr=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:04:08.132575Z","iopub.execute_input":"2026-02-13T02:04:08.133071Z","iopub.status.idle":"2026-02-13T02:04:08.152279Z","shell.execute_reply.started":"2026-02-13T02:04:08.133032Z","shell.execute_reply":"2026-02-13T02:04:08.151631Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"results_quad = []\n\ncommon_models = sorted(set(best_models_valence.keys()) & set(best_models_arousal.keys()))\n\nfor name in common_models:\n    model_val = best_models_valence[name]\n    model_aro = best_models_arousal[name]\n\n    v_pred = model_val.predict(X_test_val)\n    a_pred = model_aro.predict(X_test_aro)\n\n    y_pred_quad = quadrant_vec(v_pred, a_pred, thr=0.5)\n\n    acc = accuracy_score(y_true_quad, y_pred_quad)\n\n    # weighted metrics\n    f1 = f1_score(y_true_quad, y_pred_quad, average=\"weighted\")\n    prec, rec, _, _ = precision_recall_fscore_support(\n        y_true_quad,\n        y_pred_quad,\n        average=\"weighted\",\n        zero_division=0\n    )\n\n    results_quad.append({\n        \"Model\": name,\n        \"Accuracy\": float(acc),\n        \"Precision\": float(prec),\n        \"Recall\": float(rec),\n        \"F1\": float(f1),\n    })\n\nresults_quad_df = (\n    pd.DataFrame(results_quad)\n    .sort_values(\"F1\", ascending=False)\n    .reset_index(drop=True)\n)\n\ndisplay(results_quad_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:04:08.154114Z","iopub.execute_input":"2026-02-13T02:04:08.154595Z","iopub.status.idle":"2026-02-13T02:04:08.310010Z","shell.execute_reply.started":"2026-02-13T02:04:08.154573Z","shell.execute_reply":"2026-02-13T02:04:08.309510Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"           Model  Accuracy  Precision    Recall        F1\n0            SVR  0.675325   0.705470  0.675325  0.657283\n1        XGBoost  0.675325   0.670199  0.675325  0.650618\n2          Ridge  0.649351   0.685862  0.649351  0.632791\n3  Random Forest  0.662338   0.763943  0.662338  0.627722\n4            kNN  0.649351   0.520276  0.649351  0.575765","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVR</td>\n      <td>0.675325</td>\n      <td>0.705470</td>\n      <td>0.675325</td>\n      <td>0.657283</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBoost</td>\n      <td>0.675325</td>\n      <td>0.670199</td>\n      <td>0.675325</td>\n      <td>0.650618</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ridge</td>\n      <td>0.649351</td>\n      <td>0.685862</td>\n      <td>0.649351</td>\n      <td>0.632791</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>0.662338</td>\n      <td>0.763943</td>\n      <td>0.662338</td>\n      <td>0.627722</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kNN</td>\n      <td>0.649351</td>\n      <td>0.520276</td>\n      <td>0.649351</td>\n      <td>0.575765</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"results_quad_df.to_csv('PMEmo_classification_from_regression_weighted.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:04:08.311535Z","iopub.execute_input":"2026-02-13T02:04:08.311724Z","iopub.status.idle":"2026-02-13T02:04:08.316454Z","shell.execute_reply.started":"2026-02-13T02:04:08.311709Z","shell.execute_reply":"2026-02-13T02:04:08.315707Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"# Linear regression","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nres_df = pd.read_csv('/kaggle/input/pmemo-cls-wighted-results/PMEmo_classification_from_regression_weighted.csv')\n\n#Russell model of emotion\ndef assign_quadrant(valence, arousal, thr=0.5):\n    if valence <= thr and arousal <= thr:\n        return 2\n    elif valence > thr and arousal <= thr:\n        return 3\n    elif valence <= thr and arousal > thr:\n        return 1\n    else:\n        return 0\n\ndef quadrant_vec(v, a, thr=0.5):\n    v = np.asarray(v).ravel()\n    a = np.asarray(a).ravel()\n    return np.array([assign_quadrant(v[i], a[i], thr=thr) for i in range(len(v))], dtype=int)\n    \ny_true_quad = quadrant_vec(y_test_val, y_test_aro, thr=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:26:59.189283Z","iopub.execute_input":"2026-02-13T04:26:59.189656Z","iopub.status.idle":"2026-02-13T04:26:59.198227Z","shell.execute_reply.started":"2026-02-13T04:26:59.189633Z","shell.execute_reply":"2026-02-13T04:26:59.197596Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def reg_metrics(y_true, y_pred):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n    \n\n#Valence LinearRegression\nlin_val = LinearRegression()\nlin_val.fit(X_train_val, y_train_val)\nv_pred = lin_val.predict(X_test_val)\nmae_v, rmse_v, r2_v = reg_metrics(y_test_val, v_pred)\nprint(f\"LinearReg (Valence): MAE={mae_v:.4f} RMSE={rmse_v:.4f} R2={r2_v:.4f}\")\n\n\n#Arousal LinearRegression\nlin_aro = LinearRegression()\nlin_aro.fit(X_train_aro, y_train_aro)\na_pred = lin_aro.predict(X_test_aro)\nmae_a, rmse_a, r2_a = reg_metrics(y_test_aro, a_pred)\nprint(f\"LinearReg (Arousal): MAE={mae_a:.4f} RMSE={rmse_a:.4f} R2={r2_a:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:41:15.563993Z","iopub.execute_input":"2026-02-13T04:41:15.564737Z","iopub.status.idle":"2026-02-13T04:41:15.697121Z","shell.execute_reply.started":"2026-02-13T04:41:15.564713Z","shell.execute_reply":"2026-02-13T04:41:15.696374Z"}},"outputs":[{"name":"stdout","text":"LinearReg (Valence): MAE=0.1365 RMSE=0.1694 R2=-0.0761\nLinearReg (Arousal): MAE=0.1186 RMSE=0.1684 R2=0.1327\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"results_quad = []\n\n# --- predictions ---\nv_pred = lin_val.predict(X_test_val)\na_pred = lin_aro.predict(X_test_aro)\n\n# --- quadrant conversion ---\ny_pred_quad = quadrant_vec(v_pred, a_pred, thr=0.5)\n\n# --- classification metrics ---\nacc = accuracy_score(y_true_quad, y_pred_quad)\n\nf1 = f1_score(y_true_quad, y_pred_quad, average=\"weighted\")\n\nprec, rec, _, _ = precision_recall_fscore_support(\n    y_true_quad,\n    y_pred_quad,\n    average=\"weighted\",\n    zero_division=0\n)\n\nresults_quad.append({\n    \"Model\": \"Linear Regression\",\n    \"Accuracy\": float(acc),\n    \"Precision\": float(prec),\n    \"Recall\": float(rec),\n    \"F1\": float(f1),\n})\n\nresults_quad_df = pd.DataFrame(results_quad)\n\ndisplay(results_quad_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:41:20.862669Z","iopub.execute_input":"2026-02-13T04:41:20.862937Z","iopub.status.idle":"2026-02-13T04:41:20.881237Z","shell.execute_reply.started":"2026-02-13T04:41:20.862919Z","shell.execute_reply":"2026-02-13T04:41:20.880663Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"               Model  Accuracy  Precision    Recall        F1\n0  Linear Regression  0.649351   0.740628  0.649351  0.681641","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>0.649351</td>\n      <td>0.740628</td>\n      <td>0.649351</td>\n      <td>0.681641</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"results = pd.concat([res_df, results_quad_df]).sort_values(\"Accuracy\", ascending=False).reset_index(drop = True)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:41:58.369717Z","iopub.execute_input":"2026-02-13T04:41:58.370226Z","iopub.status.idle":"2026-02-13T04:41:58.380990Z","shell.execute_reply.started":"2026-02-13T04:41:58.370203Z","shell.execute_reply":"2026-02-13T04:41:58.380395Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"               Model  Accuracy  Precision    Recall        F1\n0                SVR  0.675325   0.705470  0.675325  0.657283\n1            XGBoost  0.675325   0.670199  0.675325  0.650618\n2      Random Forest  0.662338   0.763943  0.662338  0.627722\n3              Ridge  0.649351   0.685862  0.649351  0.632791\n4                kNN  0.649351   0.520276  0.649351  0.575765\n5  Linear Regression  0.649351   0.740628  0.649351  0.681641","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVR</td>\n      <td>0.675325</td>\n      <td>0.705470</td>\n      <td>0.675325</td>\n      <td>0.657283</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBoost</td>\n      <td>0.675325</td>\n      <td>0.670199</td>\n      <td>0.675325</td>\n      <td>0.650618</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>0.662338</td>\n      <td>0.763943</td>\n      <td>0.662338</td>\n      <td>0.627722</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ridge</td>\n      <td>0.649351</td>\n      <td>0.685862</td>\n      <td>0.649351</td>\n      <td>0.632791</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kNN</td>\n      <td>0.649351</td>\n      <td>0.520276</td>\n      <td>0.649351</td>\n      <td>0.575765</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Linear Regression</td>\n      <td>0.649351</td>\n      <td>0.740628</td>\n      <td>0.649351</td>\n      <td>0.681641</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"results.to_csv('PMEmo_audio.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T04:42:32.383837Z","iopub.execute_input":"2026-02-13T04:42:32.384486Z","iopub.status.idle":"2026-02-13T04:42:32.393214Z","shell.execute_reply.started":"2026-02-13T04:42:32.384463Z","shell.execute_reply":"2026-02-13T04:42:32.392605Z"}},"outputs":[],"execution_count":20}]}