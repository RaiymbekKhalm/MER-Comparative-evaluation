{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10735576,"sourceType":"datasetVersion","datasetId":6656507}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport time\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif, f_regression\nfrom skopt import BayesSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sentence_transformers import SentenceTransformer\n\n\nANNOTATIONS_PATH = \"/kaggle/input/datasets/rkhalm/pmemo2019/PMEmo2019/annotations/static_annotations.csv\"\nLYRICS_PATH = \"/kaggle/input/datasets/rkhalm/pmemo2019/PMEmo2019/lyrics\"\nFEATURES_PATH = \"/kaggle/input/datasets/rkhalm/pmemo2019/PMEmo2019/features/static_features.csv\"\n\n\nannotations = pd.read_csv(ANNOTATIONS_PATH)\nfeatures = pd.read_csv(FEATURES_PATH)\n\nannotations = annotations.sort_values(\"musicId\").reset_index(drop=True)\nfeatures = features.sort_values(\"musicId\").reset_index(drop=True)\n\nmerged = pd.merge(features, annotations, on=\"musicId\", how=\"inner\")\n\n\ndef load_lyrics(music_id):\n    path = os.path.join(LYRICS_PATH, f\"{music_id}.lrc\")\n    try:\n        with open(path, encoding=\"utf-8\") as f:\n            return f.read()\n    except:\n        return \"\"\n\nmerged[\"lyrics\"] = merged[\"musicId\"].apply(load_lyrics).fillna(\"\")\n\n\n\n#Text cleaning\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n    text = re.sub(r\"\\d+\", \"\", text)\n    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\nmerged[\"clean_lyrics\"] = merged[\"lyrics\"].apply(clean_text)\n\n\n#BERT embeddings\nencoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\nX_text = encoder.encode(merged[\"clean_lyrics\"].tolist(), show_progress_bar=True)\n\n\n#Targets\ny_val = merged[\"Valence(mean)\"].values\ny_aro = merged[\"Arousal(mean)\"].values\n\n\n#Audio features\nX_audio_raw = merged.drop(columns=[\n    \"musicId\",\n    \"Arousal(mean)\",\n    \"Valence(mean)\",\n    \"lyrics\",\n    \"clean_lyrics\"\n]).values\n\n\n#Split\nidx = np.arange(len(merged))\nidx_train, idx_test = train_test_split(idx, test_size=0.2, random_state=42)\n\nX_audio_train = X_audio_raw[idx_train]\nX_audio_test = X_audio_raw[idx_test]\n\nX_text_train = X_text[idx_train]\nX_text_test = X_text[idx_test]\n\ny_val_train, y_val_test = y_val[idx_train], y_val[idx_test]\ny_aro_train, y_aro_test = y_aro[idx_train], y_aro[idx_test]\n\n\n#Scaling\nscaler = StandardScaler()\nX_audio_train_sc = scaler.fit_transform(X_audio_train)\nX_audio_test_sc = scaler.transform(X_audio_test)\n\nk = min(400, X_audio_train_sc.shape[1])\n\n\n#Feature selection\nselector_val = SelectKBest(f_regression, k=k)\nX_audio_train_val = selector_val.fit_transform(X_audio_train_sc, y_val_train)\nX_audio_test_val = selector_val.transform(X_audio_test_sc)\n\nselector_aro = SelectKBest(f_regression, k=k)\nX_audio_train_aro = selector_aro.fit_transform(X_audio_train_sc, y_aro_train)\nX_audio_test_aro = selector_aro.transform(X_audio_test_sc)\n\n\n#Early fusion\nX_train_val = np.hstack([X_text_train, X_audio_train_val])\nX_test_val  = np.hstack([X_text_test,  X_audio_test_val])\n\nX_train_aro = np.hstack([X_text_train, X_audio_train_aro])\nX_test_aro  = np.hstack([X_text_test,  X_audio_test_aro])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:57:58.407620Z","iopub.execute_input":"2026-02-13T00:57:58.408009Z","iopub.status.idle":"2026-02-13T00:58:03.427022Z","shell.execute_reply.started":"2026-02-13T00:57:58.407978Z","shell.execute_reply":"2026-02-13T00:58:03.426367Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2750e9953c12455596c9818c5a6765c1"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom skopt import BayesSearchCV\n\nmodels = {\n    'Ridge': (\n        Ridge(),\n        {'alpha': (1e-3, 1e+3, 'log-uniform')}\n    ),\n\n    'SVR': (\n        SVR(),\n        {\n            'C': (1e-3, 1e+3, 'log-uniform'),\n            'gamma': (1e-4, 1e-1, 'log-uniform'),\n            'kernel': ['rbf']\n        }\n    ),\n\n    'Random Forest': (\n        RandomForestRegressor(),\n        {\n            'n_estimators': (100, 1000),\n            'max_depth': (5, 50),\n            'min_samples_split': (2, 20),\n            'min_samples_leaf': (1, 10)\n        }\n    ),\n\n    'XGBoost': (\n        XGBRegressor(\n            objective='reg:squarederror',\n            tree_method='hist',\n            device='cuda'\n        ),\n        {\n            'n_estimators': (100, 1000),\n            'max_depth': (3, 15),\n            'learning_rate': (1e-2, 3e-1, 'log-uniform'),\n            'subsample': (0.5, 1.0),\n            'colsample_bytree': (0.5, 1.0)\n        }\n    ),\n\n    'k-Nearest Neighbors': (\n        KNeighborsRegressor(),\n        {\n            'n_neighbors': (1, 30),\n            'weights': ['uniform', 'distance'],\n            'p': [1, 2]\n        }\n    )\n}\n\n\ndef reg_metrics(y_true, y_pred):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n\nresults_val = []\ntrained_models_val = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:58:03.428083Z","iopub.execute_input":"2026-02-13T00:58:03.428343Z","iopub.status.idle":"2026-02-13T00:58:03.440004Z","shell.execute_reply.started":"2026-02-13T00:58:03.428317Z","shell.execute_reply":"2026-02-13T00:58:03.439379Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# VALENCE REGRESSION","metadata":{}},{"cell_type":"code","source":"for name, (model, param_grid) in tqdm(models.items()):\n    print(f\"\\nTraining {name}...\")\n\n    pipeline = Pipeline([('model', model)])\n\n    opt = BayesSearchCV(\n        estimator=pipeline,\n        search_spaces={'model__' + k: v for k, v in param_grid.items()},\n        n_iter=40,\n        scoring='neg_root_mean_squared_error',  # оптимизируем RMSE\n        cv=3,\n        n_jobs=-1,\n        verbose=0,\n        random_state=42,\n        refit=True,\n    )\n\n    opt.fit(X_train_val, y_val_train)\n\n    y_pred = opt.predict(X_test_val)\n\n    mae, rmse, r2 = reg_metrics(y_val_test, y_pred)\n\n    print(f\"Model: {name}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n\n    results_val.append({\n        'Model': name,\n        'Best Params': opt.best_params_,\n        'MAE': float(mae),\n        'RMSE': float(rmse),\n        'R2': float(r2),\n        'Best CV (neg_RMSE)': float(opt.best_score_),\n    })\n\n    trained_models_val[name] = opt\n\nresults_val_df = pd.DataFrame(results_val).sort_values(by='RMSE', ascending=True)\ndisplay(results_val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T00:58:03.440975Z","iopub.execute_input":"2026-02-13T00:58:03.441423Z","iopub.status.idle":"2026-02-13T02:31:52.881634Z","shell.execute_reply.started":"2026-02-13T00:58:03.441392Z","shell.execute_reply":"2026-02-13T02:31:52.880847Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nTraining Ridge...\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 1/5 [00:26<01:47, 26.82s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Ridge, MAE: 0.0902, RMSE: 0.1149, R2: 0.4360\n\nTraining SVR...\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [00:59<01:30, 30.27s/it]","output_type":"stream"},{"name":"stdout","text":"Model: SVR, MAE: 0.0901, RMSE: 0.1135, R2: 0.4494\n\nTraining Random Forest...\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [1:17:00<1:09:57, 2098.93s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.0890, RMSE: 0.1121, R2: 0.4626\n\nTraining XGBoost...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [02:15:18] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [02:15:20] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [02:15:20] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [02:15:34] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [02:31:24] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  return func(**kwargs)\n 80%|████████  | 4/5 [1:33:21<27:37, 1657.67s/it]  /usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/skopt/space/space.py:116: UserWarning: Dimension [1, 2] was inferred to Integer(low=1, high=2, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1, 2), prior=None). See the documentation of the check_dimension function for the upcoming API.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.0875, RMSE: 0.1089, R2: 0.4931\n\nTraining k-Nearest Neighbors...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [1:33:49<00:00, 1125.88s/it]","output_type":"stream"},{"name":"stdout","text":"Model: k-Nearest Neighbors, MAE: 0.0914, RMSE: 0.1146, R2: 0.4388\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 Model                                        Best Params  \\\n3              XGBoost  {'model__colsample_bytree': 0.6549662025178873...   \n2        Random Forest  {'model__max_depth': 9, 'model__min_samples_le...   \n1                  SVR  {'model__C': 0.5130480864902878, 'model__gamma...   \n4  k-Nearest Neighbors  {'model__n_neighbors': 27, 'model__p': 2, 'mod...   \n0                Ridge               {'model__alpha': 356.05207413580825}   \n\n        MAE      RMSE        R2  Best CV (neg_RMSE)  \n3  0.087496  0.108900  0.493087           -0.112645  \n2  0.088986  0.112127  0.462603           -0.116551  \n1  0.090135  0.113492  0.449439           -0.113329  \n4  0.091368  0.114584  0.438790           -0.119051  \n0  0.090221  0.114874  0.435952           -0.112594  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>R2</th>\n      <th>Best CV (neg_RMSE)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.6549662025178873...</td>\n      <td>0.087496</td>\n      <td>0.108900</td>\n      <td>0.493087</td>\n      <td>-0.112645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 9, 'model__min_samples_le...</td>\n      <td>0.088986</td>\n      <td>0.112127</td>\n      <td>0.462603</td>\n      <td>-0.116551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>{'model__C': 0.5130480864902878, 'model__gamma...</td>\n      <td>0.090135</td>\n      <td>0.113492</td>\n      <td>0.449439</td>\n      <td>-0.113329</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k-Nearest Neighbors</td>\n      <td>{'model__n_neighbors': 27, 'model__p': 2, 'mod...</td>\n      <td>0.091368</td>\n      <td>0.114584</td>\n      <td>0.438790</td>\n      <td>-0.119051</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 356.05207413580825}</td>\n      <td>0.090221</td>\n      <td>0.114874</td>\n      <td>0.435952</td>\n      <td>-0.112594</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"results_val_df.to_csv('valence_regression_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:31:52.883849Z","iopub.execute_input":"2026-02-13T02:31:52.884178Z","iopub.status.idle":"2026-02-13T02:31:52.892063Z","shell.execute_reply.started":"2026-02-13T02:31:52.884154Z","shell.execute_reply":"2026-02-13T02:31:52.891342Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# AROUSAL REGRESSION","metadata":{}},{"cell_type":"code","source":"import ast\nfrom sklearn.pipeline import Pipeline\n\ndef parse_best_params(x):\n    if isinstance(x, dict):\n        return x\n    if isinstance(x, str):\n        x = x.strip()\n        if not x:\n            return {}\n        return ast.literal_eval(x)\n    return {}\n\n#Model -> Best Params (FROM VALENCE TUNING)\nbest_params_map = {\n    row[\"Model\"]: parse_best_params(row[\"Best Params\"])\n    for _, row in results_val_df.iterrows()\n}\n\nresults_aro = []\ntrained_models_aro = {}\n\nfor name, (model, param_grid) in tqdm(models.items()):\n    print(f\"\\nRefit {name} with params from results_val_df...\")\n\n    if name not in best_params_map:\n        print(f\"[SKIP] {name} not found in results_val_df\")\n        continue\n\n    best_params = best_params_map[name]\n    pipeline = Pipeline([('model', model)])\n\n    if best_params:\n        pipeline.set_params(**best_params)\n\n    pipeline.fit(X_train_aro, y_aro_train)\n    y_pred = pipeline.predict(X_test_aro)\n\n    mae, rmse, r2 = reg_metrics(y_aro_test, y_pred)\n\n    print(f\"Model: {name}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n\n    results_aro.append({\n        \"Model\": name,\n        \"Best Params\": best_params,\n        \"MAE\": float(mae),\n        \"RMSE\": float(rmse),\n        \"R2\": float(r2),\n    })\n\n    trained_models_aro[name] = pipeline\n\nresults_aro_df = pd.DataFrame(results_aro).sort_values(by=\"RMSE\", ascending=True).reset_index(drop=True)\ndisplay(results_aro_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:34:46.690352Z","iopub.execute_input":"2026-02-13T02:34:46.690659Z","iopub.status.idle":"2026-02-13T02:38:41.783028Z","shell.execute_reply.started":"2026-02-13T02:34:46.690632Z","shell.execute_reply":"2026-02-13T02:38:41.782309Z"}},"outputs":[{"name":"stderr","text":" 20%|██        | 1/5 [00:00<00:00,  6.50it/s]","output_type":"stream"},{"name":"stdout","text":"\nRefit Ridge with params from results_val_df...\nModel: Ridge, MAE: 0.0732, RMSE: 0.0958, R2: 0.7293\n\nRefit SVR with params from results_val_df...\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [00:00<00:00,  7.13it/s]","output_type":"stream"},{"name":"stdout","text":"Model: SVR, MAE: 0.0758, RMSE: 0.0998, R2: 0.7060\n\nRefit Random Forest with params from results_val_df...\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [03:52<03:32, 106.22s/it]","output_type":"stream"},{"name":"stdout","text":"Model: Random Forest, MAE: 0.0747, RMSE: 0.1022, R2: 0.6922\n\nRefit XGBoost with params from results_val_df...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [03:55<00:00, 47.01s/it] ","output_type":"stream"},{"name":"stdout","text":"Model: XGBoost, MAE: 0.0718, RMSE: 0.0986, R2: 0.7130\n\nRefit k-Nearest Neighbors with params from results_val_df...\nModel: k-Nearest Neighbors, MAE: 0.0784, RMSE: 0.1043, R2: 0.6790\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 Model                                        Best Params  \\\n0                Ridge               {'model__alpha': 356.05207413580825}   \n1              XGBoost  {'model__colsample_bytree': 0.6549662025178873...   \n2                  SVR  {'model__C': 0.5130480864902878, 'model__gamma...   \n3        Random Forest  {'model__max_depth': 9, 'model__min_samples_le...   \n4  k-Nearest Neighbors  {'model__n_neighbors': 27, 'model__p': 2, 'mod...   \n\n        MAE      RMSE        R2  \n0  0.073234  0.095791  0.729315  \n1  0.071819  0.098627  0.713046  \n2  0.075768  0.099834  0.705982  \n3  0.074736  0.102153  0.692165  \n4  0.078388  0.104308  0.679038  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Best Params</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ridge</td>\n      <td>{'model__alpha': 356.05207413580825}</td>\n      <td>0.073234</td>\n      <td>0.095791</td>\n      <td>0.729315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBoost</td>\n      <td>{'model__colsample_bytree': 0.6549662025178873...</td>\n      <td>0.071819</td>\n      <td>0.098627</td>\n      <td>0.713046</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVR</td>\n      <td>{'model__C': 0.5130480864902878, 'model__gamma...</td>\n      <td>0.075768</td>\n      <td>0.099834</td>\n      <td>0.705982</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>{'model__max_depth': 9, 'model__min_samples_le...</td>\n      <td>0.074736</td>\n      <td>0.102153</td>\n      <td>0.692165</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k-Nearest Neighbors</td>\n      <td>{'model__n_neighbors': 27, 'model__p': 2, 'mod...</td>\n      <td>0.078388</td>\n      <td>0.104308</td>\n      <td>0.679038</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"results_aro_df.to_csv('arousal_regression_results.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:39:11.842168Z","iopub.execute_input":"2026-02-13T02:39:11.843330Z","iopub.status.idle":"2026-02-13T02:39:11.849791Z","shell.execute_reply.started":"2026-02-13T02:39:11.843246Z","shell.execute_reply":"2026-02-13T02:39:11.848888Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# import umap.umap_ as umap\n# import pandas as pd\n\n# # Преобразуем в DataFrame для удобства\n# df_vis = pd.DataFrame(X_text)\n# df_vis['label'] = y_quadrant\n\n# # Возьмем равное число примеров из каждого класса\n# sampled_df = df_vis.groupby('label').sample(n=25, random_state=42)\n# X_sample = sampled_df.drop(columns='label').values\n# y_sample = sampled_df['label'].values\n\n\n# import matplotlib.pyplot as plt\n# import umap.umap_ as umap\n\n# # UMAP-проекция в 2D\n# reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', random_state=42)\n# X_umap = reducer.fit_transform(X_sample)\n\n# # Визуализация\n# plt.figure(figsize=(10, 7))\n# scatter = plt.scatter(\n#     X_umap[:, 0], X_umap[:, 1],\n#     c=y_sample,\n#     cmap='tab10',    # 10 классов\n#     alpha=0.8,\n#     s=50             # размер точек\n# )\n# plt.colorbar(scatter, label='Emotion Quadrant')\n# plt.title(\"UMAP Visualization\")\n# plt.xlabel(\"UMAP 1\")\n# plt.ylabel(\"UMAP 2\")\n# plt.grid(True)\n# plt.tight_layout()\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T02:34:32.557261Z","iopub.status.idle":"2026-02-13T02:34:32.557620Z","shell.execute_reply.started":"2026-02-13T02:34:32.557494Z","shell.execute_reply":"2026-02-13T02:34:32.557512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n\n#Russell model of emotion\ndef assign_quadrant(valence, arousal, thr=0.5):\n    if valence <= thr and arousal <= thr:\n        return 2\n    elif valence > thr and arousal <= thr:\n        return 3\n    elif valence <= thr and arousal > thr:\n        return 1\n    else:\n        return 0\n\ndef quadrant_vec(v, a, thr=0.5):\n    v = np.asarray(v).ravel()\n    a = np.asarray(a).ravel()\n    return np.array([assign_quadrant(v[i], a[i], thr=thr) for i in range(len(v))], dtype=int)\n    \ny_true_quad = quadrant_vec(y_val_test, y_aro_test, thr=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:05:40.762066Z","iopub.execute_input":"2026-02-13T03:05:40.762500Z","iopub.status.idle":"2026-02-13T03:05:40.768898Z","shell.execute_reply.started":"2026-02-13T03:05:40.762469Z","shell.execute_reply":"2026-02-13T03:05:40.768223Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ndef reg_metrics(y_true, y_pred):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n\ntrained_models_val = dict(trained_models_val)\ntrained_models_aro = dict(trained_models_aro)\n\n#Valence LinearRegression\nlin_val = LinearRegression()\nlin_val.fit(X_train_val, y_val_train)\nv_pred = lin_val.predict(X_test_val)\nmae_v, rmse_v, r2_v = reg_metrics(y_val_test, v_pred)\nprint(f\"LinearReg (Valence): MAE={mae_v:.4f} RMSE={rmse_v:.4f} R2={r2_v:.4f}\")\n\ntrained_models_val[\"Linear Regression\"] = lin_val\n\n#Arousal LinearRegression\nlin_aro = LinearRegression()\nlin_aro.fit(X_train_aro, y_aro_train)\na_pred = lin_aro.predict(X_test_aro)\nmae_a, rmse_a, r2_a = reg_metrics(y_aro_test, a_pred)\nprint(f\"LinearReg (Arousal): MAE={mae_a:.4f} RMSE={rmse_a:.4f} R2={r2_a:.4f}\")\n\ntrained_models_aro[\"Linear Regression\"] = lin_aro","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:14:32.443271Z","iopub.execute_input":"2026-02-13T03:14:32.444049Z","iopub.status.idle":"2026-02-13T03:14:32.733390Z","shell.execute_reply.started":"2026-02-13T03:14:32.444020Z","shell.execute_reply":"2026-02-13T03:14:32.732689Z"}},"outputs":[{"name":"stdout","text":"LinearReg (Valence): MAE=0.2829 RMSE=0.3615 R2=-4.5849\nLinearReg (Arousal): MAE=0.2956 RMSE=0.3784 R2=-3.2232\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"results_quad = []\n\ncommon_models = sorted(set(trained_models_val.keys()) & set(trained_models_aro.keys()))\n\nfor name in common_models:\n    model_val = trained_models_val[name]\n    model_aro = trained_models_aro[name]\n\n    v_pred = model_val.predict(X_test_val)\n    a_pred = model_aro.predict(X_test_aro)\n\n    y_pred_quad = quadrant_vec(v_pred, a_pred, thr=0.5)\n\n    acc = accuracy_score(y_true_quad, y_pred_quad)\n\n    # weighted metrics\n    f1 = f1_score(y_true_quad, y_pred_quad, average=\"weighted\")\n    prec, rec, _, _ = precision_recall_fscore_support(\n        y_true_quad,\n        y_pred_quad,\n        average=\"weighted\",\n        zero_division=0\n    )\n\n    results_quad.append({\n        \"Model\": name,\n        \"Accuracy\": float(acc),\n        \"Precision\": float(prec),\n        \"Recall\": float(rec),\n        \"F1\": float(f1),\n    })\n\nresults_quad_df = (\n    pd.DataFrame(results_quad)\n    .sort_values(\"F1\", ascending=False)\n    .reset_index(drop=True)\n)\n\ndisplay(results_quad_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:14:32.735370Z","iopub.execute_input":"2026-02-13T03:14:32.737035Z","iopub.status.idle":"2026-02-13T03:14:33.055354Z","shell.execute_reply.started":"2026-02-13T03:14:32.737002Z","shell.execute_reply":"2026-02-13T03:14:33.054529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                 Model  Accuracy  Precision    Recall        F1\n0  k-Nearest Neighbors  0.733766   0.719599  0.733766  0.722466\n1                  SVR  0.707792   0.720119  0.707792  0.711370\n2              XGBoost  0.714286   0.704842  0.714286  0.708026\n3                Ridge  0.714286   0.702381  0.714286  0.704919\n4        Random Forest  0.707792   0.705535  0.707792  0.703739\n5    Linear Regression  0.454545   0.589375  0.454545  0.498079","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>k-Nearest Neighbors</td>\n      <td>0.733766</td>\n      <td>0.719599</td>\n      <td>0.733766</td>\n      <td>0.722466</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVR</td>\n      <td>0.707792</td>\n      <td>0.720119</td>\n      <td>0.707792</td>\n      <td>0.711370</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBoost</td>\n      <td>0.714286</td>\n      <td>0.704842</td>\n      <td>0.714286</td>\n      <td>0.708026</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ridge</td>\n      <td>0.714286</td>\n      <td>0.702381</td>\n      <td>0.714286</td>\n      <td>0.704919</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random Forest</td>\n      <td>0.707792</td>\n      <td>0.705535</td>\n      <td>0.707792</td>\n      <td>0.703739</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Linear Regression</td>\n      <td>0.454545</td>\n      <td>0.589375</td>\n      <td>0.454545</td>\n      <td>0.498079</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"results_quad_df.to_csv('PMEmo_FUSION_classification_from_regression_weighted_final.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T03:15:03.749993Z","iopub.execute_input":"2026-02-13T03:15:03.750713Z","iopub.status.idle":"2026-02-13T03:15:03.755449Z","shell.execute_reply.started":"2026-02-13T03:15:03.750681Z","shell.execute_reply":"2026-02-13T03:15:03.754858Z"}},"outputs":[],"execution_count":23}]}